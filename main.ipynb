{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome,ChromeOptions\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "import math\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = ChromeOptions()\n",
    "\n",
    "options.add_argument(r\"user-data-dir=C:\\Users\\abhay\\Desktop\\CG (CMP513, CMP514)\\Project - COPY\\browser\")\n",
    "# options.add_argument(\"--headless\")\n",
    "options.add_argument('--log-level=1')\n",
    "\n",
    "browser = Chrome(options=options)\n",
    "wait = WebDriverWait(browser, 3)\n",
    "action = ActionChains(browser)\n",
    "\n",
    "\n",
    "browser.get(\"https://open.spotify.com/\")\n",
    "\n",
    "try:\n",
    "    if wait.until(EC.element_to_be_clickable((By.CLASS_NAME, \"ButtonInner-sc-14ud5tc-0.kwEVAz.encore-inverted-light-set\"))).text == \"Log in\":\n",
    "        logged_in = False\n",
    "except:\n",
    "    logged_in = True\n",
    "\n",
    "if not logged_in:\n",
    "    print(\"User is not logged in. Restarting in non-headless mode.\")\n",
    "    browser.quit()\n",
    "\n",
    "    options = ChromeOptions()\n",
    "    options.add_argument(r\"user-data-dir=C:\\Users\\abhay\\Desktop\\CG (CMP513, CMP514)\\Project - COPY\\browser\")\n",
    "\n",
    "    browser = Chrome(options=options)\n",
    "    browser.get(r\"https://accounts.spotify.com/en/login\")\n",
    "\n",
    "    br = True\n",
    "    while(br):\n",
    "        try: \n",
    "            for text in browser.find_elements(By.CLASS_NAME, \"encore-text.encore-text-body-medium-bold.sc-iKTcqh.doOTMr\"):\n",
    "                if text.text == \"Web Player\":\n",
    "                    br = False\n",
    "        except:\n",
    "            time.sleep(2)\n",
    "    browser.quit()\n",
    "\n",
    "    options = ChromeOptions()\n",
    "    options.add_argument(r\"user-data-dir=C:\\Users\\abhay\\Desktop\\CG (CMP513, CMP514)\\Project - COPY\\browser\")\n",
    "    options.add_argument(\"--headless\")\n",
    "\n",
    "    browser = Chrome(options=options)\n",
    "    wait = WebDriverWait(browser, 10)\n",
    "    browser.get(r\"https://open.spotify.com/\")\n",
    "else:\n",
    "    print(\"User is already logged in. Continuing in headless mode.\")\n",
    "\n",
    "main_hub = browser.find_element(By.CLASS_NAME, \"yglmI5m3fCc8baD1Kwdw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_only_index_and_middle_extended(landmarks):\n",
    "    index_extended = landmarks[8].y < landmarks[6].y \n",
    "    middle_extended = landmarks[12].y < landmarks[10].y\n",
    "    ring_closed = landmarks[16].y > landmarks[14].y \n",
    "    pinky_closed = landmarks[20].y > landmarks[18].y\n",
    "    \n",
    "    return index_extended and middle_extended and ring_closed and pinky_closed\n",
    "\n",
    "def is_only_thumb_and_index_extended(landmarks):\n",
    "    thumb_extended = landmarks[4].x > landmarks[3].x \n",
    "    index_extended = landmarks[8].y < landmarks[6].y\n",
    "    middle_closed = landmarks[11].y > landmarks[9].y\n",
    "    ring_closed = landmarks[15].y > landmarks[13].y\n",
    "    pinky_closed = landmarks[19].y > landmarks[17].y\n",
    "\n",
    "    return thumb_extended and index_extended and middle_closed and ring_closed and pinky_closed\n",
    "\n",
    "def get_thumb_index_distance_action(landmarks, last_volume_time, min_distance=0.1, max_distance=0.21, cooldown = 0.7):\n",
    "    thumb_x, thumb_y = landmarks[4].x, landmarks[4].y\n",
    "    index_x, index_y = landmarks[8].x, landmarks[8].y\n",
    "    \n",
    "    # Calculate Euclidean distance between thumb and index finger\n",
    "    distance = math.sqrt((index_x - thumb_x) ** 2 + (index_y - thumb_y) ** 2)\n",
    "\n",
    "    current_time = time.time()\n",
    "    if current_time - last_volume_time < cooldown:\n",
    "        return False\n",
    "    \n",
    "    # Determine action based on the distance\n",
    "    if distance > max_distance:\n",
    "        last_volume_time = current_time\n",
    "        return \"volume up\"\n",
    "    elif distance < min_distance:\n",
    "        return \"volume down\"\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def is_hand_still(current_position, last_position, last_movement_time, still_threshold=0.01, still_duration=1):\n",
    "    distance = ((current_position[0] - last_position[0]) ** 2 + (current_position[1] - last_position[1]) ** 2) ** 0.5\n",
    "    \n",
    "    current_time = time.time()\n",
    "\n",
    "    if distance < still_threshold:\n",
    "        if current_time - last_movement_time >= still_duration:\n",
    "            return True, current_time\n",
    "    else:\n",
    "        last_movement_time = current_time\n",
    "\n",
    "    return False, last_movement_time\n",
    "\n",
    "def detect_swipe(previous_position, current_position, swipe_threshold=0.08):\n",
    "    distance_moved = abs(current_position[0] - previous_position[0])\n",
    "\n",
    "    if distance_moved > swipe_threshold:\n",
    "        swipe_direction = 'left' if current_position[0] < previous_position[0] else 'right'\n",
    "        return swipe_direction\n",
    "    return None\n",
    "\n",
    "def is_fist_closed(landmarks, right_hand):\n",
    "    # Check if the hand is closed into a fist AND if it is facing the camera\n",
    "    return (landmarks[8].y > landmarks[7].y > landmarks[6].y and \n",
    "            landmarks[12].y > landmarks[11].y > landmarks[9].y and\n",
    "            landmarks[16].y > landmarks[15].y > landmarks[13].y and\n",
    "            landmarks[20].y > landmarks[19].y > landmarks[17].y and\n",
    "            landmarks[4].x < landmarks[3].x and\n",
    "            is_facing_camera(landmarks, right_hand))\n",
    "\n",
    "def is_palm_open(landmarks, right_hand):\n",
    "    # Check if the hand is open, palm facing outward AND if it is facing the camera\n",
    "    return (landmarks[4].y < landmarks[3].y < landmarks[2].y < landmarks[1].y and   # Thumb\n",
    "            landmarks[8].y < landmarks[7].y < landmarks[6].y < landmarks[5].y and   # Index finger\n",
    "            landmarks[12].y < landmarks[11].y < landmarks[10].y < landmarks[9].y and  # Middle finger\n",
    "            landmarks[16].y < landmarks[15].y < landmarks[14].y < landmarks[13].y and # Ring finger\n",
    "            landmarks[20].y < landmarks[19].y < landmarks[18].y < landmarks[17].y and # Pinky finger\n",
    "            is_facing_camera(landmarks, right_hand))\n",
    "\n",
    "def is_facing_camera(landmarks, right_hand):    \n",
    "    if right_hand:\n",
    "        return (landmarks[5].x > landmarks[9].x > landmarks[13].x > landmarks[17].x)\n",
    "    else:  # Left hand\n",
    "        return (landmarks[5].x < landmarks[9].x < landmarks[13].x < landmarks[17].x)\n",
    "\n",
    "def send_command(command):\n",
    "    try:\n",
    "        main_hub.find_element(By.CLASS_NAME, \"gQoa8JTSpjSmYyABcag2.encore-bright-accent-set.T3hkVxXuSbCYOD2GIeQd\")\n",
    "    except:\n",
    "        return \"No Devices Available\"\n",
    "    \n",
    "    if command == \"play\":\n",
    "        if main_hub.find_element(By.CLASS_NAME, \"Button-sc-qlcn5g-0.iJUiBm\").get_attribute(\"aria-label\") == \"Play\":\n",
    "            main_hub.find_element(By.CLASS_NAME, \"Button-sc-qlcn5g-0.iJUiBm\").click()\n",
    "            return \"Play\"\n",
    "        else:\n",
    "            return \"Device is already playing.\"\n",
    "    \n",
    "    elif command == \"pause\":\n",
    "        if main_hub.find_element(By.CLASS_NAME, \"Button-sc-qlcn5g-0.iJUiBm\").get_attribute(\"aria-label\") == \"Pause\":\n",
    "            main_hub.find_element(By.CLASS_NAME, \"Button-sc-qlcn5g-0.iJUiBm\").click()\n",
    "            return \"Pause\"\n",
    "        else:\n",
    "            return \"Device is already pasued.\"\n",
    "\n",
    "    elif command == \"next_track\":\n",
    "        side_hub = main_hub.find_element(By.CLASS_NAME, \"Qt226Z4rBQs53aedRQBQ\")\n",
    "        for button in side_hub.find_elements(By.CLASS_NAME, \"Button-sc-1dqy6lx-0.dmdXQN\"):\n",
    "            if button.get_attribute(\"data-testid\") == \"control-button-skip-forward\":\n",
    "                button.click()\n",
    "                return \"Next track\"\n",
    "\n",
    "    elif command == \"prev_track\":\n",
    "        song_name = main_hub.find_element(By.XPATH, \"//*[@id=\\\"main\\\"]/div/div[2]/div[3]/footer/div[1]/div[1]/div/div[2]/div[1]/div/div/div/div/span/a\").text\n",
    "        side_hub = main_hub.find_element(By.CLASS_NAME, \"NKUrT1GciYXAEEUtagN1\")\n",
    "        for button in side_hub.find_elements(By.CLASS_NAME, \"Button-sc-1dqy6lx-0.dmdXQN\"):\n",
    "            if button.get_attribute(\"data-testid\") == \"control-button-skip-back\":\n",
    "                button.click()\n",
    "                try:\n",
    "                    WebDriverWait(browser, 0.8).until(EC.element_to_be_clickable((\"\")))\n",
    "                except:\n",
    "                    if song_name == main_hub.find_element(By.XPATH, \"//*[@id=\\\"main\\\"]/div/div[2]/div[3]/footer/div[1]/div[1]/div/div[2]/div[1]/div/div/div/div/span/a\").text:\n",
    "                        button.click()\n",
    "                    return \"Previous track\"\n",
    "    \n",
    "    elif command == \"volume_up\":\n",
    "        value = float(main_hub.find_element(By.CLASS_NAME, \"G4n5bTzWUvlftzDwrFVG.ExuDUBJ7bk8vT6INnm9F\").find_element(By.TAG_NAME, \"input\").get_attribute(\"value\"))\n",
    "        if value == 1:\n",
    "            return \"Max Volume\"\n",
    "        value+=0.1\n",
    "        slider = main_hub.find_element(By.CLASS_NAME, \"G4n5bTzWUvlftzDwrFVG.ExuDUBJ7bk8vT6INnm9F\").find_element(By.CLASS_NAME, \"tIr7C6B0Pt6YKdOnqaqj\")\n",
    "        slider_size = slider.size\n",
    "        action.move_to_element_with_offset(slider, (0 - slider_size['width'] / 2) + slider_size['width'] * value, 0).click().perform()\n",
    "        return f\"Volume: {str(value*100)[0:2]}%\"\n",
    "        \n",
    "    elif command == \"volume_down\":\n",
    "        value = float(main_hub.find_element(By.CLASS_NAME, \"G4n5bTzWUvlftzDwrFVG.ExuDUBJ7bk8vT6INnm9F\").find_element(By.TAG_NAME, \"input\").get_attribute(\"value\"))\n",
    "        if value == 0:\n",
    "            return \"Min Volume\"\n",
    "        value-=0.1\n",
    "        slider = main_hub.find_element(By.CLASS_NAME, \"G4n5bTzWUvlftzDwrFVG.ExuDUBJ7bk8vT6INnm9F\").find_element(By.CLASS_NAME, \"tIr7C6B0Pt6YKdOnqaqj\")\n",
    "        slider_size = slider.size\n",
    "        action.move_to_element_with_offset(slider, (0 - slider_size['width'] / 2) + slider_size['width'] * value, 0).click().perform()\n",
    "        return f\"Volume: {str(value*100)[0:2]}%\"\n",
    "        \n",
    "\n",
    "command_queue = queue.Queue()\n",
    "\n",
    "def send_command_thread(command):\n",
    "    # Worker function to execute command and put the result in the queue\n",
    "    def worker():\n",
    "        result = send_command(command)\n",
    "        command_queue.put(result)\n",
    "        \n",
    "    \n",
    "    # Start the thread\n",
    "    thread = threading.Thread(target=worker)\n",
    "    thread.start()\n",
    "    return thread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.7)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "previous_position = None\n",
    "last_movement_time = time.time()\n",
    "last_volume_time = time.time()\n",
    "hand_ready_for_swipe = False\n",
    "last_fist_time = time.time()\n",
    "last_palm_time = time.time()\n",
    "fist_detected = False\n",
    "palm_detected = False\n",
    "hand_ready_for_gesture = False\n",
    "\n",
    "song_name = main_hub.find_element(By.XPATH, \"//*[@id=\\\"main\\\"]/div/div[2]/div[3]/footer/div[1]/div[1]/div/div[2]/div[1]/div/div/div/div/span/a\").text\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        continue\n",
    "\n",
    "    results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    # image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "            \n",
    "            index_finger_tip = hand_landmarks.landmark[12]\n",
    "            current_position = (index_finger_tip.x, index_finger_tip.y)\n",
    "\n",
    "            if previous_position is None:\n",
    "                previous_position = current_position\n",
    "\n",
    "            if is_only_index_and_middle_extended(hand_landmarks.landmark):\n",
    "                hand_still, last_movement_time = is_hand_still(current_position, previous_position, last_movement_time,  still_duration=0.2)\n",
    "                if hand_still:\n",
    "                    hand_ready_for_swipe = True\n",
    "                if hand_ready_for_swipe:\n",
    "                    swipe_direction = detect_swipe(previous_position, current_position)\n",
    "                    if swipe_direction == 'left':\n",
    "                        last_movement_time = time.time()\n",
    "                        send_command_thread(\"prev_track\")\n",
    "                        print(\"Swipe left detected: Previous track\")\n",
    "                        hand_ready_for_swipe = False\n",
    "                        previous_position = current_position\n",
    "                    elif swipe_direction == 'right':\n",
    "                        last_movement_time = time.time()\n",
    "                        send_command_thread(\"next_track\")\n",
    "                        print(\"Swipe right detected: Next track\")\n",
    "                        hand_ready_for_swipe = False\n",
    "                        previous_position = current_position\n",
    "\n",
    "            if is_fist_closed(hand_landmarks.landmark, results.multi_handedness[0].classification[0].label[0] == \"L\"):\n",
    "                hand_still, last_movement_time = is_hand_still(current_position, previous_position, last_movement_time)\n",
    "                \n",
    "                if hand_still:\n",
    "                    hand_ready_for_gesture = True\n",
    "                if hand_ready_for_gesture and not fist_detected:\n",
    "                    last_fist_time = time.time()\n",
    "                    fist_detected = True\n",
    "                elif fist_detected and time.time() - last_fist_time > 1:\n",
    "                    last_movement_time = time.time()\n",
    "                    send_command_thread(\"pause\")\n",
    "                    print(\"Fist closed: Pausing\")\n",
    "                    hand_ready_for_gesture = False\n",
    "                    fist_detected = False\n",
    "            else:\n",
    "                fist_detected = False\n",
    "\n",
    "            if is_palm_open(hand_landmarks.landmark, results.multi_handedness[0].classification[0].label[0] == \"L\"):\n",
    "                hand_still, last_movement_time = is_hand_still(current_position, previous_position, last_movement_time)\n",
    "                \n",
    "                if hand_still:\n",
    "                    hand_ready_for_gesture = True\n",
    "                if hand_ready_for_gesture and not palm_detected:\n",
    "                    last_palm_time = time.time()\n",
    "                    palm_detected = True\n",
    "                elif palm_detected and time.time() - last_palm_time > 1:\n",
    "                    last_movement_time = time.time()\n",
    "                    send_command_thread(\"play\")\n",
    "                    print(\"Open palm: Playing\")\n",
    "                    hand_ready_for_gesture = False\n",
    "                    palm_detected = False\n",
    "            else:\n",
    "                palm_detected = False\n",
    "\n",
    "            if is_only_thumb_and_index_extended(hand_landmarks.landmark):\n",
    "                volume = get_thumb_index_distance_action(hand_landmarks.landmark, last_volume_time)\n",
    "                if volume == \"volume up\":\n",
    "                    last_volume_time = time.time()\n",
    "                    send_command_thread(\"volume_up\")\n",
    "                elif volume == \"volume down\":\n",
    "                    last_volume_time = time.time()\n",
    "                    send_command_thread(\"volume_down\")\n",
    "            \n",
    "\n",
    "            previous_position = current_position\n",
    "    elif hand_ready_for_swipe or hand_ready_for_gesture:\n",
    "        hand_ready_for_swipe = False\n",
    "        hand_ready_for_gesture = False\n",
    "\n",
    "    cv2.imshow('Hand Gesture Control', image)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.7)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "previous_position = None\n",
    "last_movement_time = time.time()\n",
    "last_volume_time = time.time()\n",
    "hand_ready_for_swipe = False\n",
    "last_fist_time = time.time()\n",
    "last_palm_time = time.time()\n",
    "fist_detected = False\n",
    "palm_detected = False\n",
    "hand_ready_for_gesture = False\n",
    "command_text = None\n",
    "command_display_time = 3\n",
    "command_last_time = time.time() - command_display_time\n",
    "\n",
    "song_name = main_hub.find_element(By.XPATH, \"//*[@id=\\\"main\\\"]/div/div[2]/div[3]/footer/div[1]/div[1]/div/div[2]/div[1]/div/div/div/div/span/a\").text\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        continue\n",
    "\n",
    "    results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    # image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # Gesture detection logic\n",
    "            index_finger_tip = hand_landmarks.landmark[12]\n",
    "            current_position = (index_finger_tip.x, index_finger_tip.y)\n",
    "\n",
    "            if previous_position is None:\n",
    "                previous_position = current_position\n",
    "\n",
    "            # Check for swipe gestures\n",
    "            if is_only_index_and_middle_extended(hand_landmarks.landmark):\n",
    "                hand_still, last_movement_time = is_hand_still(current_position, previous_position, last_movement_time, still_duration=0.2)\n",
    "                if hand_still:\n",
    "                    hand_ready_for_swipe = True\n",
    "                if hand_ready_for_swipe:\n",
    "                    swipe_direction  = detect_swipe(previous_position, current_position)\n",
    "                    if swipe_direction == 'left':\n",
    "                        last_movement_time = time.time()\n",
    "                        send_command_thread(\"prev_track\")\n",
    "                        command_last_time = time.time()\n",
    "                        hand_ready_for_swipe = False\n",
    "                    elif swipe_direction == 'right':\n",
    "                        last_movement_time = time.time()\n",
    "                        send_command_thread(\"next_track\")\n",
    "                        command_last_time = time.time()\n",
    "                        hand_ready_for_swipe = False\n",
    "                        previous_position = current_position\n",
    "\n",
    "            # Check for fist (pause) gesture\n",
    "            if is_fist_closed(hand_landmarks.landmark, results.multi_handedness[0].classification[0].label[0] == \"L\"):\n",
    "                hand_still, last_movement_time = is_hand_still(current_position, previous_position, last_movement_time)\n",
    "                \n",
    "                if hand_still:\n",
    "                    hand_ready_for_gesture = True\n",
    "                if hand_ready_for_gesture and not fist_detected:\n",
    "                    last_fist_time = time.time()\n",
    "                    fist_detected = True\n",
    "                elif fist_detected and time.time() - last_fist_time > 1:\n",
    "                    last_movement_time = time.time()\n",
    "                    send_command_thread(\"pause\")\n",
    "                    command_last_time = time.time()\n",
    "                    hand_ready_for_gesture = False\n",
    "                    fist_detected = False\n",
    "            else:\n",
    "                fist_detected = False\n",
    "\n",
    "            if is_palm_open(hand_landmarks.landmark, results.multi_handedness[0].classification[0].label[0] == \"L\"):\n",
    "                hand_still, last_movement_time = is_hand_still(current_position, previous_position, last_movement_time)\n",
    "                \n",
    "                if hand_still:\n",
    "                    hand_ready_for_gesture = True\n",
    "                if hand_ready_for_gesture and not palm_detected:\n",
    "                    last_palm_time = time.time()\n",
    "                    palm_detected = True\n",
    "                elif palm_detected and time.time() - last_palm_time > 1:\n",
    "                    last_movement_time = time.time()\n",
    "                    send_command_thread(\"play\")\n",
    "                    command_last_time = time.time()\n",
    "                    hand_ready_for_gesture = False\n",
    "                    palm_detected = False\n",
    "            else:\n",
    "                palm_detected = False\n",
    "\n",
    "            if is_only_thumb_and_index_extended(hand_landmarks.landmark):\n",
    "                volume = get_thumb_index_distance_action(hand_landmarks.landmark, last_volume_time)\n",
    "                if volume == \"volume up\":\n",
    "                    last_volume_time = time.time()\n",
    "                    send_command_thread(\"volume_up\")\n",
    "                elif volume == \"volume down\":\n",
    "                    last_volume_time = time.time()\n",
    "                    send_command_thread(\"volume_down\")\n",
    "\n",
    "            previous_position = current_position\n",
    "    elif hand_ready_for_swipe or hand_ready_for_gesture:\n",
    "        hand_ready_for_swipe = False\n",
    "        hand_ready_for_gesture = False\n",
    "\n",
    "    # Display song name\n",
    "    cv2.putText(image, f\"Song: {song_name}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    if not command_queue.empty():\n",
    "        command_text = command_queue.get()\n",
    "        command_last_time = time.time()\n",
    "        \n",
    "\n",
    "    if time.time() - command_last_time < command_display_time:\n",
    "        try:\n",
    "            song_name_element = wait.until(EC.visibility_of_element_located(\n",
    "            (By.XPATH, \"//*[@id=\\\"main\\\"]/div/div[2]/div[3]/footer/div[1]/div[1]/div/div[2]/div[1]/div/div/div/div/span/a\")\n",
    "        ))\n",
    "            song_name = song_name_element.text \n",
    "        finally:\n",
    "            cv2.putText(image, command_text, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    else:\n",
    "        command_text = None\n",
    "    # Show the image in the window\n",
    "    cv2.imshow('Hand Gesture Control', image)\n",
    "\n",
    "    # Exit on pressing 'ESC'\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.7)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "previous_position = None\n",
    "last_movement_time = time.time()\n",
    "last_volume_time = time.time()\n",
    "hand_ready_for_swipe = False\n",
    "last_fist_time = time.time()\n",
    "last_palm_time = time.time()\n",
    "fist_detected = False\n",
    "palm_detected = False\n",
    "hand_ready_for_gesture = False\n",
    "command_text = None\n",
    "command_display_time = 3\n",
    "command_last_time = time.time() - command_display_time\n",
    "song_name = \"\"\n",
    "\n",
    "# Global variables\n",
    "cap2 = None  # Second video capture\n",
    "is_playing = False\n",
    "volume = 50  # Initial volume level (0-100)\n",
    "video_size = (300, 200)  # Desired size of the video (width, height)\n",
    "\n",
    "# Dictionary of actions to their corresponding video files\n",
    "video_files = {\n",
    "    \"play\": r\"Gesture_Video\\play.mp4\",  # Replace with your actual video paths\n",
    "    \"pause\": r\"Gesture_Video\\Pause.mp4\",\n",
    "    \"next\": r\"Gesture_Video\\Next.mp4\",\n",
    "    \"prev\": r\"Gesture_Video\\previous.mp4\",\n",
    "    \"volume_up\": r\"Gesture_Video\\Volume up.mp4\",\n",
    "    \"volume_down\": r\"Gesture_Video\\Volume down.mp4\",\n",
    "}\n",
    "\n",
    "def start_video(video_name):\n",
    "    global cap2, is_playing\n",
    "    if cap2 is not None:  # Only release if cap2 is already initialized\n",
    "        cap2.release()  # Release any previously opened video capture\n",
    "        is_playing = False\n",
    "    cap2 = cv2.VideoCapture(video_files[video_name])\n",
    "    if not cap2.isOpened():\n",
    "        print(f\"Error: Could not open video {video_files[video_name]}\")\n",
    "        return\n",
    "    is_playing = True\n",
    "    update_video2()\n",
    "\n",
    "def update_video2():\n",
    "    \"\"\"Update the small window with the current frame of the video.\"\"\"\n",
    "    global cap2, is_playing\n",
    "    if is_playing and cap2 is not None:\n",
    "        ret, frame = cap2.read()\n",
    "        if ret:\n",
    "            # Resize the frame to the desired dimensions\n",
    "            frame_resized = cv2.resize(frame, video_size)\n",
    "            frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
    "            img = Image.fromarray(frame_rgb)\n",
    "            imgtk = ImageTk.PhotoImage(image=img)\n",
    "            video_label2.imgtk = imgtk\n",
    "            video_label2.config(image=imgtk)\n",
    "        else:\n",
    "            # Video has finished, dispose of it\n",
    "            cap2.release()  # Release the video capture\n",
    "            is_playing = False\n",
    "    # Update every 30ms\n",
    "    video_label2.after(60, update_video2)\n",
    "\n",
    "def update_info_panel():\n",
    "    \"\"\"Update the information panel text.\"\"\"\n",
    "    global song_name\n",
    "    try:\n",
    "        song_name_element = wait.until(EC.visibility_of_element_located((By.XPATH, \"//*[@id=\\\"main\\\"]/div/div[2]/div[3]/footer/div[1]/div[1]/div/div[2]/div[1]/div/div/div/div/span/a\")))\n",
    "        song_name = song_name_element.text\n",
    "    except:\n",
    "        song_name = \"Error Fetching Song Name\"\n",
    "    finally:\n",
    "        info_text.set(song_name)\n",
    "        root.after(1000, update_info_panel)\n",
    "    \n",
    "def update_command():\n",
    "    global command_last_time, command_text\n",
    "    if not command_queue.empty():\n",
    "        command_text = command_queue.get()\n",
    "        command_last_time = time.time()\n",
    "\n",
    "    if not time.time() - command_last_time < command_display_time:\n",
    "        command_text = \"\"\n",
    "    info_text2.set(command_text)\n",
    "    root.after(500, update_command)\n",
    "\n",
    "# Set up the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Spotify Gesture Control\")\n",
    "root.geometry(\"1200x500\")\n",
    "\n",
    "# Main webcam feed frame (left side)\n",
    "video_frame = tk.Frame(root, width=600, height=600)\n",
    "video_frame.pack(side=\"left\", padx=10, pady=10)\n",
    "\n",
    "video_label = tk.Label(video_frame)\n",
    "video_label.pack()\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not access the webcam.\")\n",
    "    exit()\n",
    "\n",
    "# Info panel (right side)\n",
    "info_frame = tk.Frame(root, width=400, height=150, bg=\"#f0f0f0\")\n",
    "info_frame.pack(side=\"top\", fill=\"x\", padx=10, pady=10)\n",
    "\n",
    "# Song name label (larger font, bold, centered)\n",
    "info_label = tk.Label(info_frame, text=\"Spotify Gesture Control\", font=(\"Arial\", 16, \"bold\"), bg=\"#f0f0f0\")\n",
    "info_label.pack(pady=5)\n",
    "\n",
    "# Song name display\n",
    "info_text = tk.StringVar()\n",
    "info_text.set(\"Loading song...\")  # Initial placeholder\n",
    "song_label = tk.Label(info_frame, textvariable=info_text, font=(\"Arial\", 18), bg=\"#f0f0f0\", fg=\"#333\")\n",
    "song_label.pack(pady=5)\n",
    "\n",
    "# Command performed display (smaller font, lighter color)\n",
    "info_text2 = tk.StringVar()\n",
    "info_text2.set(\"Awaiting gesture...\")  # Initial placeholder for commands\n",
    "command_label = tk.Label(info_frame, textvariable=info_text2, font=(\"Arial\", 14), bg=\"#f0f0f0\", fg=\"#666\")\n",
    "command_label.pack(pady=5)\n",
    "\n",
    "# Control panel (bottom-right, video and buttons)\n",
    "control_frame = tk.Frame(root, width=400, height=250, bg=\"#f2f2f2\")\n",
    "control_frame.pack(side=\"bottom\", fill=\"x\", padx=20, pady=20)\n",
    "\n",
    "# Small video playback window (top-right of the control panel)\n",
    "# Create the small_video_frame with fixed size and prevent resizing\n",
    "small_video_frame = tk.Frame(control_frame, width=300, height=180, bg=\"#333333\", relief=\"solid\", borderwidth=2)\n",
    "small_video_frame.pack(side=\"top\", padx=20, pady=10)\n",
    "\n",
    "# Prevent the frame from resizing to fit its contents\n",
    "small_video_frame.pack_propagate(False)\n",
    "\n",
    "# Add video label inside small_video_frame (will stay centered)\n",
    "video_label2 = tk.Label(small_video_frame, fg=\"white\", bg=\"white\")\n",
    "video_label2.pack(fill=\"both\", expand=True)\n",
    "\n",
    "# Create a label below the small_video_frame for the \"View Gesture\" text\n",
    "view_gesture_label = tk.Label(control_frame, text=\"View Gesture\", font=(\"Arial\", 12))\n",
    "view_gesture_label.pack(side=\"top\", pady=5)\n",
    "\n",
    "\n",
    "# Buttons for control (each button triggers its own video)\n",
    "button_style = {'width': 12, 'height': 1, 'font': ('Arial', 12), 'relief': 'raised', 'bd': 2, 'bg': '#4CAF50', 'fg': 'white'}\n",
    "\n",
    "# Buttons in the control panel\n",
    "# Frame for the first row of buttons, centered\n",
    "row1_frame = tk.Frame(control_frame)\n",
    "row1_frame.pack(side=\"top\", padx=10, pady=5, anchor=\"center\")\n",
    "\n",
    "# Add buttons to the first row\n",
    "play_button = tk.Button(row1_frame, text=\"Play\", command=lambda: start_video(\"play\"), **button_style)\n",
    "play_button.pack(side=\"left\", padx=10)\n",
    "\n",
    "next_button = tk.Button(row1_frame, text=\"Next Track\", command=lambda: start_video(\"next\"), **button_style)\n",
    "next_button.pack(side=\"left\", padx=10)\n",
    "\n",
    "prev_button = tk.Button(row1_frame, text=\"Previous Track\", command=lambda: start_video(\"prev\"), **button_style)\n",
    "prev_button.pack(side=\"left\", padx=10)\n",
    "\n",
    "# Frame for the second row of buttons\n",
    "row2_frame = tk.Frame(control_frame)\n",
    "row2_frame.pack(side=\"top\", padx=10, pady=5, anchor=\"center\")\n",
    "\n",
    "pause_button = tk.Button(row2_frame, text=\"Pause\", command=lambda: start_video(\"pause\"), **button_style)\n",
    "pause_button.pack(side=\"left\", padx=10)\n",
    "\n",
    "# Add buttons to the second row\n",
    "volume_up_button = tk.Button(row2_frame, text=\"Volume Up\", command=lambda: start_video(\"volume_up\"), **button_style)\n",
    "volume_up_button.pack(side=\"left\", padx=10)\n",
    "\n",
    "volume_down_button = tk.Button(row2_frame, text=\"Volume Down\", command=lambda: start_video(\"volume_down\"), **button_style)\n",
    "volume_down_button.pack(side=\"left\", padx=10)\n",
    "\n",
    "# Start the main video stream (webcam)\n",
    "def update_video():\n",
    "    global previous_position, last_movement_time, last_volume_time, hand_ready_for_swipe, last_fist_time, last_palm_time, fist_detected, palm_detected, hand_ready_for_gesture, command_last_time\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        return\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = hands.process(frame_rgb)\n",
    "    # image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame_rgb, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "            \n",
    "            index_finger_tip = hand_landmarks.landmark[12]\n",
    "            current_position = (index_finger_tip.x, index_finger_tip.y)\n",
    "\n",
    "            if previous_position is None:\n",
    "                previous_position = current_position\n",
    "\n",
    "            if is_only_index_and_middle_extended(hand_landmarks.landmark):\n",
    "                hand_still, last_movement_time = is_hand_still(current_position, previous_position, last_movement_time,  still_duration=0.2)\n",
    "                if hand_still:\n",
    "                    hand_ready_for_swipe = True\n",
    "                if hand_ready_for_swipe:\n",
    "                    swipe_direction = detect_swipe(previous_position, current_position)\n",
    "                    if swipe_direction == 'left':\n",
    "                        last_movement_time = time.time()\n",
    "                        send_command_thread(\"prev_track\")\n",
    "                        command_last_time = time.time()\n",
    "                        print(\"Swipe left detected: Previous track\")\n",
    "                        hand_ready_for_swipe = False\n",
    "                        previous_position = current_position\n",
    "                    elif swipe_direction == 'right':\n",
    "                        last_movement_time = time.time()\n",
    "                        send_command_thread(\"next_track\")\n",
    "                        command_last_time = time.time()\n",
    "                        print(\"Swipe right detected: Next track\")\n",
    "                        hand_ready_for_swipe = False\n",
    "                        previous_position = current_position\n",
    "\n",
    "            if is_fist_closed(hand_landmarks.landmark, results.multi_handedness[0].classification[0].label[0] == \"L\"):\n",
    "                hand_still, last_movement_time = is_hand_still(current_position, previous_position, last_movement_time)\n",
    "                \n",
    "                if hand_still:\n",
    "                    hand_ready_for_gesture = True\n",
    "                if hand_ready_for_gesture and not fist_detected:\n",
    "                    last_fist_time = time.time()\n",
    "                    fist_detected = True\n",
    "                elif fist_detected and time.time() - last_fist_time > 1:\n",
    "                    last_movement_time = time.time()\n",
    "                    send_command_thread(\"pause\")\n",
    "                    command_last_time = time.time()\n",
    "                    print(\"Fist closed: Pausing\")\n",
    "                    hand_ready_for_gesture = False\n",
    "                    fist_detected = False\n",
    "            else:\n",
    "                fist_detected = False\n",
    "\n",
    "            if is_palm_open(hand_landmarks.landmark, results.multi_handedness[0].classification[0].label[0] == \"L\"):\n",
    "                hand_still, last_movement_time = is_hand_still(current_position, previous_position, last_movement_time)\n",
    "                \n",
    "                if hand_still:\n",
    "                    hand_ready_for_gesture = True\n",
    "                if hand_ready_for_gesture and not palm_detected:\n",
    "                    last_palm_time = time.time()\n",
    "                    palm_detected = True\n",
    "                elif palm_detected and time.time() - last_palm_time > 1:\n",
    "                    last_movement_time = time.time()\n",
    "                    send_command_thread(\"play\")\n",
    "                    command_last_time = time.time()\n",
    "                    print(\"Open palm: Playing\")\n",
    "                    hand_ready_for_gesture = False\n",
    "                    palm_detected = False\n",
    "            else:\n",
    "                palm_detected = False\n",
    "\n",
    "            if is_only_thumb_and_index_extended(hand_landmarks.landmark):\n",
    "                volume = get_thumb_index_distance_action(hand_landmarks.landmark, last_volume_time)\n",
    "                if volume == \"volume up\":\n",
    "                    last_volume_time = time.time()\n",
    "                    send_command_thread(\"volume_up\")\n",
    "                    command_last_time = time.time()\n",
    "                elif volume == \"volume down\":\n",
    "                    last_volume_time = time.time()\n",
    "                    send_command_thread(\"volume_down\")\n",
    "                    command_last_time = time.time()\n",
    "            \n",
    "\n",
    "            previous_position = current_position\n",
    "    elif hand_ready_for_swipe or hand_ready_for_gesture:\n",
    "        hand_ready_for_swipe = False\n",
    "        hand_ready_for_gesture = False\n",
    "    \n",
    "    img = Image.fromarray(frame_rgb)\n",
    "    imgtk = ImageTk.PhotoImage(image=img)\n",
    "    video_label.imgtk = imgtk\n",
    "    video_label.config(image=imgtk)\n",
    "    video_label.after(30, update_video)\n",
    "\n",
    "# Start the video update loop for the webcam\n",
    "update_video()\n",
    "\n",
    "# Start the info panel update loop\n",
    "update_info_panel()\n",
    "\n",
    "update_command()\n",
    "\n",
    "# Start the Tkinter event loop\n",
    "root.mainloop()\n",
    "\n",
    "# Release the webcam capture when the window is closed\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
